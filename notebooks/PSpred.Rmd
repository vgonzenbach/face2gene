---
title: "Predicting PS status with 22q characteristics"
author: "Virgilio Gonzenbach"
date: "9/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      cache = TRUE, 
                      cache.path = 'cache/PSpred/', 
                      fig.path = "figures/PSpred/")
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```


```{r load}
library(dplyr)
library(tidyr)
library(FactoMineR)
library(factoextra)
library(e1071)
library(caret)
library(pander)
library(pROC)

chop_df = read.csv('data/Chop_merged_wideV_tp1.csv')
penn_df = read.csv("data/Penn_merged_wideV.csv")[,-1] %>% filter(group != "?") # 3 observations in '?' group

# Exclude columns with only zeros
get_zero_cols = function(df){
  num_zeros = df %>% sapply(function(x) x == 0) %>% colSums()
  prop_zeros = num_zeros / nrow(df)
  zero_cols = names(which(num_zeros == nrow(df)))
  return(zero_cols)
}

chop_df = chop_df %>% select(-all_of(get_zero_cols(chop_df)))
penn_df = penn_df %>% select(-all_of(get_zero_cols(penn_df)))

## Merge data
merged_df = merge(penn_df, chop_df, all = TRUE, sort = FALSE)
merged_df[ , c("age_at_photo", "visit_id")] = NULL

## Fill missing values with 0
merged_df[is.na.data.frame(merged_df)] = 0

# Set seed for reproducibility
seed=42
set.seed(seed)
```

## 1. Exploring characteristics of 22q sample with PCA

### Scree

```{r}
resPCA = PCA(chop_df[,-c(1:7)], scale.unit = FALSE, graph = FALSE, ncp=length(chop_df[,-c(1:7)]))
fviz_screeplot(resPCA)
```

### Loadings

```{r}
get_loadings = function(resPCA, dim=1){
  # Extract metrics from PCA object
  r = resPCA$var$coord[,dim] / sqrt(resPCA$eig[dim,1])
  
  # is equal to 
  return(r)
}

plot_loadings = function(resPCA, dim=1){
  # Plot loadings
  r = get_loadings(resPCA, dim)
  filter = r^2 > mean(r^2, na.rm = TRUE) # only include loadings with more than average contributions
  
  # Prep data
  df = data.frame(var=names(r), cor = r, row.names = NULL)[filter, ] %>% drop_na()
  df = df[order(df$cor, decreasing = TRUE),]
  df$var = factor(df$var, levels = rev(df$var)) #order before plotting
  
  # Plot
  title = sprintf("PC%s contributions", dim)
  p = df %>% ggplot(aes(x=var, y=cor)) + geom_col() + coord_flip() + 
    xlab("Gestalt Score") + ylab("Loading") + ggtitle(title) + 
    theme_bw() + theme(axis.text.y = element_text(size=10))
  return(p)
}
```

#### PC1

```{r, fig.width=12, fig.height=8}
plot_loadings(resPCA, dim=1)
```

#### PC2

```{r, fig.width=12, fig.height=8}
plot_loadings(resPCA, dim=2)
```

#### PC3

```{r, fig.width=12, fig.height=8}
plot_loadings(resPCA, dim=3)
```

#### PC4

```{r, fig.width=12, fig.height=8}
plot_loadings(resPCA, dim=4)
```

## 2. Testing for differences in 22q-like factor scores between PS and NC

For an $SVD(X) = UDV^T$, multiplied matrix of relevant gestalt scores from PS and NC groups (i.e. matrix $G$) by matrix $V$: $GV$. Examined first 4 components.

```{r}
demographics = c("bbl_id", "case_id", "sex", "race", "age", "age_at_photo")
df = penn_df %>% select(-c(all_of(demographics)))
df$group = recode(df$group, SZ = "PS", CR = "PS")

weigh_scores = function(df, coefs){
  #' Returns a linear combination of named scores included in 'coefs' 
  #' If named scores in coefs are not defined in df, columns are initialized with 0
  
  # which gestalt scores are missing from penn_df? i.e. PS and NC groups
  nohits = names(coefs)[which(!(names(coefs) %in% colnames(df)))] 
  df[, nohits] = 0 # set missing to zero to define columns
  
  # linear combination of gestalt scores
  gscores.mat = as.matrix(df[, names(coefs)])
  weighted_score = as.vector(gscores.mat %*% coefs)
  return(weighted_score)
}

weigh_scores2 = function(df, resPCA){
  # which gestalt scores are missing from penn_df? i.e. PS and NC groups
  nohits = rownames(resPCA$var$coord)[which(!(rownames(resPCA$var$coord) %in% colnames(df)))] 
  df[, nohits] = 0 # set missing to zero to define columns
   
  gscores.mat = as.matrix(df[, rownames(resPCA$var$coord)]) 
  weighted_score = gscores.mat %*% resPCA$svd$V
  
  return(weighted_score)
}
```

### weighted score 1

```{r}
gscore1 = weigh_scores(df, get_loadings(resPCA, 1))
t.test(gscore1[df$group == "NC"], gscore1[df$group == "PS"])
```

### weighted score 2

```{r}
gscore2 = weigh_scores(df, get_loadings(resPCA, 2))
t.test(gscore2[df$group == "NC"], gscore2[df$group == "PS"])
```

### weighted score 3

```{r}
gscore3 = weigh_scores(df, get_loadings(resPCA, 3))
t.test(gscore3[df$group == "NC"], gscore3[df$group == "PS"])
```

### weighted score 4

```{r}
gscore4 = weigh_scores(df, get_loadings(resPCA, 4))
t.test(gscore4[df$group == "NC"], gscore4[df$group == "PS"])
```

### Plot of weighted scores 2 and 3

```{r}
gscores_df = data.frame(group = as.factor(df$group),
          gscore2, gscore3) 
gscores_df %>% ggplot(aes(x=gscore2, y=gscore3, color = group)) + geom_point() + 
  geom_point(data = gscores_df %>% group_by(group) %>% summarize_all(mean), size = 4, shape = 17)
```

```{r}
# gscores_df = data.frame(group = as.factor(penn_df$group),
#           gscore2, gscore3) 
# gscores_df %>% filter(group!= "NC") %>%  ggplot(aes(x=gscore2, y=gscore3, color = group)) + geom_point() + 
#   geom_point(data = gscores_df %>% filter(group!= "NC") %>% group_by(group) %>% summarize_all(mean), size = 4, shape = 17)
```

## 3. Predicting PS status based on 22q-like components 2 and 3

independent 10-fold crossvalidation to pick best cost parameter for SVM.

```{r}
library(e1071)

# Determine cost w. cross-validation
set.seed(42)
tune.out = tune(svm, group ~ ., data=gscores_df, kernel="linear", type = "C-classification",
                ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
cost.opt = tune.out$best.model$cost
```

#### ROC of weighted scores 2 and 3 to predict PS vs NC


```{r}
svm.fit = svm(group ~ ., data=gscores_df, kernel="linear", type="C-classification", cost = cost.opt, decision.values=TRUE)
resROC1 = roc(gscores_df$group, as.vector(svm.fit$decision.values))
```

```{r}
svm.fit = svm(group ~ ., data=gscores_df, kernel="linear", type="C-classification", cost = cost.opt, decision.values=TRUE)
log.fit = glm(group ~ ., data=gscores_df, family=binomial)

resROC1 = roc(gscores_df$group, as.vector(svm.fit$decision.values))
resROC2 = roc(response = gscores_df$group, predictor = log.fit$fitted.values)

plotROCs = function(roc1, roc2, main, legends){
  plot(roc1, col="blue", main=main)
  plot(roc2, col="red", add=TRUE)
  legend("bottomright", 
    legend = legends, 
    col = c("blue", "red"), 
    pch = c(17,19), 
    bty = "n", 
    pt.cex = 2, 
    cex = 1.2, 
    text.col = "black", 
    horiz = F , 
    inset = c(0.1, 0.1))
  roc.test(roc1, roc2, method = "delong")
}

plotROCs(resROC1, resROC2, main = "ROC curves of PS vs NC based on 22q-like weighted scores 2 and 3", legends = c("SVM", "Logistic regression"))

```

Different direction is being set for the 2nd ROC. Issues?

##### Cross-validated ROC

10-fold cross-validation stratified by group was performed to produce out-of-sample predictions for the whole data set. Results were concatenated (and ordered) to plot a "cross-validated" ROC curve.

Note: Same folds used for all cross-validated ROCs

```{r}
cv.roc = function(df, folds, model=c("svm", "log.reg")){
  fitted = vector(mode="double")
  for(fold.ind in folds){
    train_df = df[-fold.ind, ]
    test_df = df[fold.ind, ]
  
    # fit svm
    if(model=="svm"){
      svm.fit = svm(group ~ ., data = train_df, kernel="linear", type="C-classification", cost = cost.opt)
      fitted = c(fitted, as.vector(attributes(predict(svm.fit, test_df, decision.values = TRUE))$decision.values))
    }else if(model=="log.reg"){
      log.fit = glm(group ~ ., data=train_df, family = binomial)
      fitted = c(fitted, predict(log.fit, test_df))
    }#else log.reg
  }
  
  fitted = fitted[unname(unlist(folds))]
  res = roc(df$group, fitted)
  return(res)
}

set.seed(42)
folds = createFolds(gscores_df$group, k=10)

resROC_SVM.CV = cv.roc(gscores_df, folds, "svm")
resROC_log.CV = cv.roc(gscores_df, folds, "log.reg")

plotROCs(resROC_SVM.CV, resROC_log.CV, main="ROC curves of PS vs NC with on 22q-like weighted scores 2 and 3 (CV)", legends=c("SVM", "Log.Reg"))
```

AUC dependent on cross

Seed = 1

```{r}
set.seed(1)
folds.e = createFolds(gscores_df$group, k=10)
cv.roc(gscores_df, folds.e, "svm")
```

Seed = 2

```{r}
set.seed(23)
folds.e = createFolds(gscores_df$group, k=10)
cv.roc(gscores_df, folds.e, "svm")
```

#### ROC of PS prediction based on full set of original features 

Why is AUC 1?

```{r, warning=FALSE}
penn_df4svm = data.frame(group = as.factor(recode(penn_df$group, SZ = "PS", CR = "PS")), penn_df[,-c(1:7)])

# RTune cost parameter
set.seed(42)
tune.out = tune(svm, group ~., data=penn_df4svm, kernel="linear", type = "C-classification",
                ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
cost.opt = tune.out$best.model$cost

svm.fit = svm(group ~ ., data=penn_df4svm, kernel="linear", type="C-classification", cost = cost.opt, decision.values=TRUE)

resROC_svm.full = roc(response = penn_df$group, predictor = as.vector(svm.fit$decision.values))

plot(resROC_svm.full, main="ROC curve of SVM with all original features")
auc(resROC_svm.full)
```

##### Cross validated ROC

```{r, warning=FALSE}
resROC_svm.full.cv = cv.roc(penn_df4svm, folds, "svm")
plot(resROC_svm.full.cv, main="ROC curve of SVM with all original features (SVM)")
auc(resROC_svm.full.cv)
```

Compare to ROC of SVM model with only 2nd and 3rd weighted score.

```{r}
plotROCs(resROC_SVM.CV, resROC_svm.full.cv, main="Cross-validated ROC for SVM", legends = c("2nd and 3rd weighted scores", "all orig. scores"))
```

#### With all 22q-like PCs

```{r}
# get weighted scores for all 
# SVM

gscores_df = data.frame(group = as.factor(df$group), weigh_scores2(df, resPCA))
colnames(gscores_df)[2:(ncol(gscores_df))] = paste0("gscore", 1:(length(gscores_df) - 1))

# SVM
set.seed(42)
tune.out = tune(svm, group ~., data=gscores_df, kernel="linear", type = "C-classification",
                ranges = list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
cost.opt = tune.out$best.model$cost

svm.fit = svm(group ~ ., data=gscores_df, kernel="linear", type="C-classification", cost = cost.opt, decision.values=TRUE)

resROC_svm.full = roc(response = penn_df$group, predictor = as.vector(svm.fit$decision.values))

plot(resROC_svm.full, main="ROC curve of SVM with all original features")
auc(resROC_svm.full)
```

##### Cross-validated ROC

```{r}
resROC_svm.full.cv = cv.roc(gscores_df, folds, "svm")
plotROCs(resROC_SVM.CV, resROC_svm.full.cv, main="Cross-validated ROC for SVM", legends = c("2nd and 3rd weighted scores", "all weighted scores"))
```


